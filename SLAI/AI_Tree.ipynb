{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21155c2c-c91b-4579-b4d9-5148a8d7ad81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in d:\\program files\\anaconda\\lib\\site-packages (4.7.0.68)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\90531\\appdata\\roaming\\python\\python311\\site-packages (0.10.9)\n",
      "Requirement already satisfied: scikit-learn in d:\\program files\\anaconda\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in d:\\program files\\anaconda\\lib\\site-packages (from opencv-python) (1.24.3)\n",
      "Requirement already satisfied: absl-py in d:\\program files\\anaconda\\lib\\site-packages (from mediapipe) (2.0.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in d:\\program files\\anaconda\\lib\\site-packages (from mediapipe) (22.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in d:\\program files\\anaconda\\lib\\site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: matplotlib in d:\\program files\\anaconda\\lib\\site-packages (from mediapipe) (3.7.2)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\90531\\appdata\\roaming\\python\\python311\\site-packages (from mediapipe) (4.9.0.80)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in d:\\program files\\anaconda\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\90531\\appdata\\roaming\\python\\python311\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: scipy>=1.3.2 in d:\\program files\\anaconda\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\program files\\anaconda\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\program files\\anaconda\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in d:\\program files\\anaconda\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\program files\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\program files\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\program files\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\program files\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\program files\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\program files\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in d:\\program files\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\program files\\anaconda\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pycparser in d:\\program files\\anaconda\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in d:\\program files\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python mediapipe scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0709c226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data for class 0\n",
      "Collecting data for class 1\n",
      "Collecting data for class 2\n",
      "Collecting data for class 3\n",
      "Collecting data for class 4\n",
      "Collecting data for class 5\n",
      "Collecting data for class 6\n",
      "Collecting data for class 7\n",
      "Collecting data for class 8\n",
      "Collecting data for class 9\n",
      "Collecting data for class 10\n",
      "Collecting data for class 11\n",
      "Collecting data for class 12\n",
      "Collecting data for class 13\n",
      "Collecting data for class 14\n",
      "Collecting data for class 15\n",
      "Collecting data for class 16\n",
      "Collecting data for class 17\n",
      "Collecting data for class 18\n",
      "Collecting data for class 19\n",
      "Collecting data for class 20\n",
      "Collecting data for class 21\n",
      "Collecting data for class 22\n",
      "Collecting data for class 23\n",
      "Collecting data for class 24\n",
      "Collecting data for class 25\n",
      "Collecting data for class 26\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "DATA_DIR = './data'\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "\n",
    "number_of_classes = 27\n",
    "dataset_size = 300\n",
    "\n",
    "# Kamera çözünürlüğünü ayarlayarak başlatma\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)  # Genişlik\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)  # Yükseklik\n",
    "\n",
    "for j in range(number_of_classes):\n",
    "    if not os.path.exists(os.path.join(DATA_DIR, str(j))):\n",
    "        os.makedirs(os.path.join(DATA_DIR, str(j)))\n",
    "\n",
    "    print('Collecting data for class {}'.format(j))\n",
    "\n",
    "    done = False\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.putText(frame, 'Ready? Press \"Q\" ! :)', (100, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3,\n",
    "                    cv2.LINE_AA)\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(25) == ord('q'):\n",
    "            break\n",
    "\n",
    "    counter = 0\n",
    "    while counter < dataset_size:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.imshow('frame', frame)\n",
    "        cv2.waitKey(25)\n",
    "        cv2.imwrite(os.path.join(DATA_DIR, str(j), '{}.jpg'.format(counter)), frame)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51d80052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)\n",
    "\n",
    "DATA_DIR = './data'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for dir_ in os.listdir(DATA_DIR):\n",
    "    for img_path in os.listdir(os.path.join(DATA_DIR, dir_)):\n",
    "        data_aux = []\n",
    "\n",
    "        x_ = []\n",
    "        y_ = []\n",
    "\n",
    "        img = cv2.imread(os.path.join(DATA_DIR, dir_, img_path))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = hands.process(img_rgb)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "\n",
    "                    x_.append(x)\n",
    "                    y_.append(y)\n",
    "\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "                    data_aux.append(x - min(x_))\n",
    "                    data_aux.append(y - min(y_))\n",
    "\n",
    "            data.append(data_aux)\n",
    "            labels.append(dir_)\n",
    "\n",
    "# Save the data and labels into a pickle file\n",
    "with open('data.pickle', 'wb') as f:\n",
    "    pickle.dump({'data': data, 'labels': labels}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af4c2bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% of samples were classified correctly !\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data_dict = pickle.load(open('./data.pickle', 'rb'))\n",
    "\n",
    "data = np.asarray(data_dict['data'])\n",
    "labels = np.asarray(data_dict['labels'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, shuffle=True, stratify=labels)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_predict = model.predict(x_test)\n",
    "\n",
    "score = accuracy_score(y_predict, y_test)\n",
    "\n",
    "print('{}% of samples were classified correctly !'.format(score * 100))\n",
    "\n",
    "f = open('model.p', 'wb')\n",
    "pickle.dump({'model': model}, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b509f4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "model_dict = pickle.load(open('./model.p', 'rb'))\n",
    "model = model_dict['model']\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)\n",
    "\n",
    "labels_dict = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z', 26: 'Bosluk'}\n",
    "\n",
    "while True:\n",
    "    data_aux_1 = []\n",
    "    x_1 = []\n",
    "    y_1 = []\n",
    "\n",
    "    data_aux_2 = []\n",
    "    x_2 = []\n",
    "    y_2 = []\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    H, W, _ = frame.shape\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = hands.process(frame_rgb)\n",
    "    if results.multi_hand_landmarks:\n",
    "        for i, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "            mp_drawing.draw_landmarks(\n",
    "                frame,  # image to draw\n",
    "                hand_landmarks,  # model output\n",
    "                mp_hands.HAND_CONNECTIONS,  # hand connections\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "            for j in range(len(hand_landmarks.landmark)):\n",
    "                x = hand_landmarks.landmark[j].x\n",
    "                y = hand_landmarks.landmark[j].y\n",
    "\n",
    "                if i == 0:\n",
    "                    x_1.append(x)\n",
    "                    y_1.append(y)\n",
    "                elif i == 1:\n",
    "                    x_2.append(x)\n",
    "                    y_2.append(y)\n",
    "\n",
    "            for j in range(len(hand_landmarks.landmark)):\n",
    "                x = hand_landmarks.landmark[j].x\n",
    "                y = hand_landmarks.landmark[j].y\n",
    "\n",
    "                if i == 0:\n",
    "                    data_aux_1.append(x - min(x_1))\n",
    "                    data_aux_1.append(y - min(y_1))\n",
    "                elif i == 1:\n",
    "                    data_aux_2.append(x - min(x_2))\n",
    "                    data_aux_2.append(y - min(y_2))\n",
    "\n",
    "    # Tahminler\n",
    "    if data_aux_1:\n",
    "        x1_1 = int(min(x_1) * W) - 10\n",
    "        y1_1 = int(min(y_1) * H) - 10\n",
    "        x2_1 = int(max(x_1) * W) - 10\n",
    "        y2_1 = int(max(y_1) * H) - 10\n",
    "\n",
    "        prediction_1 = model.predict([np.asarray(data_aux_1)])\n",
    "        predicted_character_1 = labels_dict[int(prediction_1[0])]\n",
    "        cv2.rectangle(frame, (x1_1, y1_1), (x2_1, y2_1), (0, 0, 0), 4)\n",
    "        cv2.putText(frame, predicted_character_1, (x1_1, y1_1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 0, 0), 3,\n",
    "                    cv2.LINE_AA)\n",
    "\n",
    "    if data_aux_2:\n",
    "        x1_2 = int(min(x_2) * W) - 10\n",
    "        y1_2 = int(min(y_2) * H) - 10\n",
    "        x2_2 = int(max(x_2) * W) - 10\n",
    "        y2_2 = int(max(y_2) * H) - 10\n",
    "\n",
    "        # Sağ elin özellik vektörlerini aynala\n",
    "        mirrored_x_2 = [W - x_val for x_val in x_2]\n",
    "        mirrored_data_aux_2 = mirrored_x_2 + y_2\n",
    "\n",
    "        prediction_2 = model.predict([np.asarray(mirrored_data_aux_2)])\n",
    "        predicted_character_2 = labels_dict[int(prediction_2[0])]\n",
    "        cv2.rectangle(frame, (x1_2, y1_2), (x2_2, y2_2), (0, 0, 0), 4)\n",
    "        cv2.putText(frame, predicted_character_2, (x1_2, y1_2 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 0, 0), 3,\n",
    "                    cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    # 'x' tuşuna basıldığında döngüden çık\n",
    "    if cv2.waitKey(1) & 0xFF == ord('x'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf5586ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eğitimde kullanılan özellik sayısı: 42\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4aba6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
